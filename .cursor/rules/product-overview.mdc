---
alwaysApply: true
---

# Product Overview

## Context

Emma Demo is a cryptocurrency chatbot application designed to showcase advanced tool selection capabilities. The core demonstration focuses on intelligent tool filtering: reducing a large pool of 100-200 available tools down to 1-10 relevant tools based on user queries.

## Purpose

- **Primary Goal**: Demonstrate sophisticated tool selection logic that intelligently filters crypto-related API tools
- **Use Case**: Analyze crypto-related data from various applications through natural language chat interface
- **Demo Focus**: Tool selection algorithm that efficiently narrows down tool candidates

## Key Features

### Chat Interface
- Single chat page with persistent chat history
- Device-based user identification (no authentication required)
- Real-time message exchange with AI assistant
- Chat list sidebar for managing multiple conversations

### Tool Management
- Tools stored in database with hierarchical structure: App â†’ Class â†’ Method
- Each method represents an API endpoint with:
  - HTTP verb (GET, POST, PUT, DELETE, etc.)
  - Path and description
  - Typed arguments with descriptions
  - Return type information
- Support for 100-200 tools across multiple crypto applications
- Admin UI at `/registered-tools` for CRUD operations
- LLM-powered seed script for generating mock tools

### Architecture Highlights
- Server Actions for all data operations
- Type-safe implementation with TypeScript
- OpenAI SDK integration (currently spoofed, to be implemented)
- PostgreSQL database with Prisma ORM

## Current State

- **âœ… Complete**: Async message processing with status tracking
- **âœ… Complete**: Optimistic UI with instant feedback
- **âœ… Complete**: Real-time polling for status updates
- **âœ… Complete**: Chat list with status icons (loading/error indicators)
- **âœ… Complete**: Tool management UI and CRUD operations
- **âœ… Complete**: LLM-powered seed script for tool generation
- **âœ… Complete**: Tool selection logic with IPC-based REPL and META_TOOLS
- **âœ… Complete**: META_TOOLS with RAG vector search and LLM Q&A
- **âœ… Complete**: Tool wrapper system with LLM processing layer
- **âœ… Complete**: OpenAI integration for chat and tool execution
- **âœ… Complete**: Vector similarity threshold tuned (0.3) for optimal results
- **âœ… Complete**: Conversational query optimization (0-tools support)
- **ðŸš§ Pending**: Actual HTTP client for tool execution (currently uses LLM simulation)
- **ðŸš§ Pending**: Full vector data population for all existing tools

## User Flow

1. User visits app â†’ Device key generated/stored in localStorage
2. User automatically gets new chat or selects existing chat
3. **User sends message** â†’ Instant optimistic UI feedback
   - Message appears immediately (no waiting)
   - Thinking animation starts instantly
   - Chat card shows loading spinner immediately
   - Chat moves to top of sidebar optimistically
4. **Backend Processing** (asynchronous, non-blocking)
   - Message saved with status "PROCESSING"
   - Tool selection via IPC-based REPL with META_TOOLS
   - Filters 100-200 tools down to 0-10 relevant tools
   - Tools execute in parallel with LLM wrapper processing
5. **Real-time Updates** â†’ Frontend polls status every 2 seconds
   - Detects when processing completes (SUCCESS/FAIL)
   - Updates chat card icon automatically
   - Shows error message if processing failed
6. **Completion** â†’ AI response appears, status cleared
7. Conversation history persists across sessions

## Technical Flow

```
User sends message (instant UI feedback)
  â†“ (0ms - optimistic)
Frontend: Message appears, spinner shows, chat moves to top
  â†“ (0ms - non-blocking)
Backend: createUserMessage â†’ setImmediate(processMessageAsync)
  â”œâ”€ User message saved
  â”œâ”€ Status set to "PROCESSING"
  â””â”€ Returns immediately (doesn't wait)
  â†“ (background processing)
processMessageAsync
  â”œâ”€ Tool Selector (selectTools)
  â”‚   â”œâ”€ Spawns child Node.js process
  â”‚   â”œâ”€ Iterative ReAct loop (1-10 steps)
  â”‚   â”œâ”€ LLM generates code using META_TOOLS
  â”‚   â””â”€ Returns 0-10 Method objects
  â”œâ”€ Chat Service (generateResponse)
  â”‚   â”œâ”€ Converts Methods to OpenAI tool format
  â”‚   â”œâ”€ Main LLM (gpt-4) decides which tools to call
  â”‚   â””â”€ Tools execute in parallel with LLM wrappers
  â”œâ”€ Creates assistant message
  â””â”€ Updates status to "SUCCESS" or "FAIL"
  â†“ (every 2 seconds)
Frontend: Polls getChatStatus â†’ Detects completion â†’ Updates UI
  â†“
User sees response, spinner disappears
```

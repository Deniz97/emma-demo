---
alwaysApply: true
---

# Product Overview

## Context

Emma Demo is a cryptocurrency chatbot application designed to showcase advanced tool selection capabilities. The core demonstration focuses on intelligent tool filtering: reducing a large pool of 100-200 available tools down to 1-10 relevant tools based on user queries.

## Purpose

- **Primary Goal**: Demonstrate sophisticated tool selection logic that intelligently filters crypto-related API tools
- **Use Case**: Analyze crypto-related data from various applications through natural language chat interface
- **Demo Focus**: Tool selection algorithm that efficiently narrows down tool candidates

## Key Features

### Chat Interface
- Single chat page with persistent chat history
- Device-based user identification (no authentication required)
- Real-time message exchange with AI assistant
- Chat list sidebar for managing multiple conversations

### Tool Management
- Tools stored in database with hierarchical structure: App â†’ Class â†’ Method
- Each method represents an API endpoint with:
  - HTTP verb (GET, POST, PUT, DELETE, etc.)
  - Path and description
  - Typed arguments with descriptions
  - Return type information
- Support for 100-200 tools across multiple crypto applications
- Admin UI at `/registered-tools` for CRUD operations
- LLM-powered seed script for generating mock tools

### Architecture Highlights
- Server Actions for all data operations
- Type-safe implementation with TypeScript
- OpenAI SDK integration (currently spoofed, to be implemented)
- PostgreSQL database with Prisma ORM

## Current State

- **âœ… Complete**: Basic chat interface and database schema
- **âœ… Complete**: Tool management UI and CRUD operations
- **âœ… Complete**: LLM-powered seed script for tool generation
- **âœ… Complete**: Tool selection logic with IPC-based REPL and META_TOOLS
- **âœ… Complete**: META_TOOLS with RAG vector search and LLM Q&A
- **âœ… Complete**: Tool wrapper system with LLM processing layer
- **âœ… Complete**: OpenAI integration for chat and tool execution
- **âœ… Complete**: End-to-end flow working with simulated tool execution
- **âœ… Complete**: Vector similarity threshold tuned (0.3) for optimal results
- **âœ… Complete**: Conversational query optimization (0-tools support)
- **âœ… Complete**: Clean, production-ready logging
- **ðŸš§ Pending**: Actual HTTP client for tool execution (currently uses LLM simulation)
- **ðŸš§ Pending**: Full vector data population for all existing tools

## User Flow

1. User visits app â†’ Device key generated/stored in localStorage
2. User automatically gets new chat or selects existing chat
3. User sends message about crypto data analysis
4. **Tool Selection**: System uses IPC-based REPL with META_TOOLS to filter 100-200 tools down to 0-10 relevant tools
   - Real Node.js child process (variables persist naturally)
   - META_TOOLS use RAG vector search (cosine similarity on embeddings)
   - LLM generates and executes code to iteratively narrow down tools
   - Can return 0 tools immediately for conversational queries
   - Returns Method objects for selected tools
5. **Tool Execution**: AI assistant calls selected tools with natural language queries
   - Each tool wrapped with gpt-3.5-turbo processing layer
   - Main model receives processed insights, never raw data
   - Tools execute in parallel for better performance
6. AI assistant generates final response using processed tool results
7. Conversation history persists across sessions

## Technical Flow

```
User Query
  â†“
Tool Selector (selectTools)
  â”œâ”€ Spawns child Node.js process
  â”œâ”€ Iterative ReAct loop (1-10 steps)
  â”œâ”€ LLM generates code using META_TOOLS
  â”œâ”€ Executes code via IPC (variables persist)
  â””â”€ Returns 0-10 Method objects
  â†“
Chat Service (generateResponse)
  â”œâ”€ Converts Methods to OpenAI tool format
  â”œâ”€ Main LLM (gpt-4) decides which tools to call
  â””â”€ Extracts query parameter for each tool
  â†“
Tool Wrapper (executeToolWithLLMWrapper)
  â”œâ”€ Executes HTTP call (mocked)
  â”œâ”€ Processes results with gpt-3.5-turbo
  â””â”€ Returns processed insights
  â†“
Main LLM generates final response
  â†“
User receives answer
```

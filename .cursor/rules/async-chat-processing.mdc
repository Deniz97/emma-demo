---
globs: app/actions/chat.ts,app/chat/**/chat-page-client.tsx,lib/chat-context.tsx,components/chat/**/*.tsx
alwaysApply: false
---

# Async Chat Processing & Optimistic UI

## Context

Chat messages are processed asynchronously in the background while providing instant UI feedback. The system uses status tracking (PROCESSING/SUCCESS/FAIL) at the Chat level and Server-Sent Events (SSE) to push updates to the UI in real-time.

## Architecture

### Status Tracking
- Chat has `lastStatus` field: `"PROCESSING" | "SUCCESS" | "FAIL" | null`
- Chat has `lastError` field: stores error message on failure
- Status set immediately when message sent, updated when processing completes

### Async Processing Flow
1. User sends message → `createUserMessage` called
2. User message created, chat status set to "PROCESSING"
3. `setImmediate()` triggers background processing
4. Frontend shows optimistic UI immediately (no waiting)
5. Backend processes asynchronously via `processMessageAsync`
6. Status updated to SUCCESS/FAIL when complete

### Real-time Updates via SSE
- Server-Sent Events push updates to client instantly (0-100ms)
- Backend emits events when status/title/messages change
- Frontend receives events via EventSource connection
- No polling intervals needed (90% reduction in HTTP requests)
- See `sse-realtime.mdc` for SSE implementation details

## Patterns

### Creating Messages (Backend)
```typescript
// app/actions/chat.ts
export async function createUserMessage(chatId, content, userId) {
  // Delete last user message if exists (prevents duplicates)
  const lastMessage = await getLastMessage(chatId);
  if (lastMessage?.role === "user") {
    await deleteMessage(lastMessage.id);
  }
  
  // Create new user message
  const userMessage = await prisma.chatMessage.create({
    data: { chatId, role: "user", content }
  });
  
  // Set status to PROCESSING
  await prisma.chat.update({
    where: { id: chatId },
    data: { lastStatus: "PROCESSING", lastError: null }
  });
  
  // Trigger async processing (non-blocking)
  setImmediate(() => {
    processMessageAsync(chatId).catch(console.error);
  });
  
  return { success: true, userMessage };
}
```

### Async Processing (Backend)
```typescript
async function processMessageAsync(chatId) {
  try {
    const chatHistory = await getChatMessages(chatId);
    const aiResponse = await generateResponse(chatHistory);
    
    // Create assistant message and update status in transaction
    await prisma.$transaction([
      prisma.chatMessage.create({
        data: { chatId, role: "assistant", content: aiResponse.content }
      }),
      prisma.chat.update({
        where: { id: chatId },
        data: { lastStatus: "SUCCESS", lastError: null }
      })
    ]);
  } catch (error) {
    await prisma.chat.update({
      where: { id: chatId },
      data: { lastStatus: "FAIL", lastError: error.message }
    });
  }
}
```

### Optimistic UI (Frontend)
```typescript
// Immediate feedback - no waiting
const handleNewMessage = async (message) => {
  // 1. Show optimistic message instantly
  setOptimisticMessage({ id: 'temp', content: message, role: 'user' });
  
  // 2. Start thinking animation
  setIsThinking(true);
  
  // 3. Update chat card status optimistically
  updateChatStatusOptimistic(chatId, "PROCESSING");
  
  // 4. Fire backend call (don't await - let it run in background)
  createUserMessage(chatId, message, userId).then((result) => {
    if (result.success) {
      // Replace optimistic with real data when ready
      refreshMessages().then(() => setOptimisticMessage(null));
      refreshSingleChat(chatId);
    }
  });
};
```

### Real-time Status Updates via SSE
```typescript
// SSE connection established in chat context
useChatEvents({
  userId,
  onEvent: handleChatEvent,
  enabled: !!userId,
});

// Handle events in chat context
const handleChatEvent = useCallback((event: ChatEvent) => {
  switch (event.type) {
    case "chat:status":
      // Update status in chat list
      setChats(prev => updateStatus(prev, event.chatId, event.data.status));
      // Refresh current chat if it's the active one
      if (event.chatId === currentChatId) refreshCurrentChat();
      break;
      
    case "message:new":
      // Refresh to show new message
      if (event.chatId === currentChatId) refreshCurrentChat();
      refreshSingleChat(event.chatId);
      break;
  }
}, [currentChatId]);

// UI state reacts to status changes automatically
useEffect(() => {
  if (currentChat?.chat?.lastStatus === "PROCESSING") {
    setIsThinking(true);
  } else {
    setIsThinking(false);
  }
}, [currentChat?.chat?.lastStatus]);
```

### Chat List Optimization
```typescript
// Optimistic update - instant, no DB call
updateChatStatusOptimistic(chatId, "PROCESSING");
// Moves chat to top, shows loading icon immediately

// Single chat refresh - efficient
refreshSingleChat(chatId);
// Only fetches one chat's metadata, not entire list

// Full refresh - used sparingly
refreshChats(userId);
// Fetches all chats, used only for initial load and polling
```

## Anti-patterns

### Don't Emit Events Before DB Writes
```typescript
// ❌ BAD - event sent before data persisted
chatEvents.emitStatusChange(userId, chatId, "SUCCESS", null);
await prisma.chat.update({
  where: { id: chatId },
  data: { lastStatus: "SUCCESS" }
});

// ✅ GOOD - emit after DB write confirms
await prisma.chat.update({
  where: { id: chatId },
  data: { lastStatus: "SUCCESS" }
});
chatEvents.emitStatusChange(userId, chatId, "SUCCESS", null);
```

### Don't Await in Message Send
```typescript
// ❌ BAD - blocks UI
await createUserMessage(chatId, message);
await refreshMessages();
setOptimisticMessage(null);

// ✅ GOOD - immediate feedback
createUserMessage(chatId, message).then(() => {
  refreshMessages().then(() => setOptimisticMessage(null));
});
```

### Don't Clear Optimistic Too Early
```typescript
// ❌ BAD - causes visual gap
setOptimisticMessage(tempMessage);
await createUserMessage();
setOptimisticMessage(null); // Cleared before real data loaded

// ✅ GOOD - wait for real data
setOptimisticMessage(tempMessage);
createUserMessage().then(() => {
  refreshMessages().then(() => setOptimisticMessage(null));
});
```

### Don't Refresh Entire List Unnecessarily
```typescript
// ❌ BAD - fetches all chats
await refreshChats(userId);

// ✅ GOOD - only one chat
refreshSingleChat(chatId);
```

### Don't Block on Status Set
```typescript
// ❌ BAD - waits for processing to complete
const response = await generateAIResponse(chatId);

// ✅ GOOD - returns immediately
setImmediate(() => processMessageAsync(chatId));
return { success: true };
```

## Best Practices

### Immediate Feedback
- Show optimistic message instantly (0ms)
- Start thinking animation immediately
- Update chat card status optimistically
- Move chat to top of list optimistically

### Silent Background Updates
- Use `refreshChats` without loading state
- Fire refreshes in background (don't await)
- Only await when absolutely necessary

### Status Icon Flow
1. Optimistic update → spinner appears instantly
2. Backend confirms → status persists
3. SSE pushes status change → icon updates instantly
4. On error → red error icon with tooltip

### Performance
- Single chat refresh instead of full list
- SSE provides instant updates (no polling overhead)
- 90% reduction in HTTP requests vs polling
- Parallel tool execution
- Real-time feedback (0-100ms latency)
- EventSource auto-manages connection lifecycle

## Key Files
- `app/actions/chat.ts`: Message creation, async processing, event emission
- `app/chat/[chatId]/chat-page-client.tsx`: SSE event handling, optimistic UI
- `lib/chat-context.tsx`: Chat list state, SSE event routing, optimistic updates
- `components/chat/chat-list.tsx`: Status icons, chat cards
- `lib/chat-events.ts`: Event emitter singleton (see `sse-realtime.mdc`)
- `app/api/chat-events/route.ts`: SSE route handler (see `sse-realtime.mdc`)

---
globs: lib/tool-selector.ts,types/tool-selector.ts,lib/repl/**/*
alwaysApply: false
---

# Tool Selection System

## Context

The tool selection system implements a ReAct-like iterative loop that uses LLM-generated code to explore and filter tools from a large pool (100-200 tools) down to 0-10 relevant tools. The system spawns a real Node.js child process via IPC, allowing variables to persist naturally across iterations without code transformations.

**Status**: ✅ Fully implemented with IPC-based REPL and clean logging

## Architecture

### Two-Stage Process
1. **ToolSelector** (`lib/tool-selector.ts`): Iteratively generates and executes code lines to select relevant tools
2. **Chat Service** (`lib/chat-service.ts`): Uses selected tools with OpenAI to generate responses and execute wrapped tools

### Core Components
- `selectTools()`: Main entry point, spawns child REPL process and implements iterative loop (max 10 steps, can stop early with 0 tools)
- `prepare_initial_context()`: Creates system and user prompts, instructs LLM about REPL persistence and 0-tools capability
- `generate_next_script()`: Uses gpt-4-turbo-preview to generate code lines and thought (including stop with empty tools)
- `executeLines()`: Executes code lines in child REPL via IPC
- `ReplSession` (`lib/repl/ReplSession.ts`): Spawns real Node.js child process, handles IPC communication
- `repl-child` (`lib/repl/repl-child.ts`): Child process with real REPL and META_TOOLS stubs
- `createReplSession()` (`lib/repl/tools.ts`): Factory function to create REPL with META_TOOLS injected
- META_TOOLS: Database query functions using RAG vector search (see `meta-tools-implementation.mdc`)

## Patterns

### System Prompt Requirements
The system prompt must instruct the LLM to:
1. Immediately return 0 tools for conversational queries (e.g., "how are you", "hello", "thanks")
2. Use `await` for all META_TOOLS calls (they are async)
3. Variables persist across iterations - can reuse them in subsequent steps
4. Use `console.log()` to output intermediate results
5. Each line should be a valid JavaScript expression or statement
6. Extract slugs from returned objects to use in subsequent calls

Example good code pattern taught to LLM (across iterations):
```typescript
// Iteration 1
const apps = await get_apps(["cryptocurrency", "bitcoin"], 5)
console.log("Found apps:", apps.length)

// Iteration 2 (apps variable is still available)
const appSlugs = apps.map(a => a.slug)
const classes = await get_classes(appSlugs, ["price"], 3)
console.log("Found classes:", classes)
```

### Iterative Loop Structure
```typescript
const session = createReplSession(); // Spawns child Node.js process
const executionHistory: ExecutionHistoryItem[] = [];
while (step < maxSteps) {
  const { lines, thought } = await generate_next_script(...);
  if (thought.stop) {
    const toolSlugs = thought.tools || []; // Can be empty for conversational queries
    return fetchMethodsBySlugs(toolSlugs);
  }
  const result = await executeLines(session, lines.lines);
  executionHistory.push({ lines, thought, result });
}
```

### IPC-Based REPL Execution
- **ReplSession** spawns real Node.js child process at start of `selectTools()`
- Child runs actual Node.js REPL (no code transformations needed)
- META_TOOLS communicate via IPC to parent process (single Prisma connection)
- Variables persist naturally in child REPL context
- 30-second timeout per tool call
- Errors don't break the session
- Clean, minimal logging

### Tool Identification
- **Always use slugs**, never IDs or names
- Slugs are required, unique fields on App/Class/Method models
- ToolSelector returns Method objects fetched by slugs

### META_TOOLS Interface
All META_TOOLS functions are now fully implemented:
- Search functions: Use RAG vector search with cosine similarity
- Interactive functions: Use gpt-3.5-turbo to answer questions about entities
- All use slugs for entity identification
- See `lib/meta-tools/` directory for implementations

### Logging
All functions include comprehensive logging with `[tool-selector]` prefix:
- Entry/exit of `selectTools()` with query and max steps
- Each iteration step with number and status
- Code execution results and errors
- Tool discovery and database retrieval
- Max steps exhaustion warnings

## Anti-patterns

### Don't Use IDs or Names
- ❌ `get_methods_by_id(methodIds: string[])`
- ✅ `get_method_details(..., method_ids: string[], ...)` (uses slugs internally)

### Don't Create Multiple REPL Sessions
- ❌ Creating new session per iteration spawns new child process
- ✅ Create once, reuse throughout all iterations

### Don't Hardcode Tool Lists
- ❌ Return all tools without filtering
- ✅ Use META_TOOLS to iteratively narrow down based on query

### Don't Skip Execution History
- ❌ Generate code without context from previous iterations
- ✅ Always pass `executionHistory` to `generate_next_script()`

## Best Practices

### Performance & Security
- Max 10 iterations (typically completes in 1-4 steps)
- Conversational queries: 0 tools in 1 step
- IPC overhead: ~1-5ms per message
- Single Prisma connection (parent process)
- 30-second timeout per tool call
- Child process isolation (no direct filesystem/network access)
- All inputs validated before DB queries

### Logging
- Minimal: query start, tool count, errors only
- Clean production output

### Testing
- Test conversational queries (should return 0 tools in 1 step)
- Test various query types (specific, broad, ambiguous)
- Monitor logs for errors

## Key Types

- `ThoughtDto`: `{ stop: boolean, tools?: string[], reasoning?: string }`
- `ToolSelectorResult`: Returns `{ tools: Method[], reasoning: string, debugData }`
- Method objects fetched by slugs for downstream processing
